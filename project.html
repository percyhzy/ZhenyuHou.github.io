<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Research Projects - Zhenyu Hou</title>
    <link rel="stylesheet" href="style.css">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Font Awesome for modern icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
</head>
<body>
    <div class="container">
        <!-- 侧边栏 -->
        <div class="sidebar">
            <div class="profile-image-container">
                <img src="images/me.jpg" alt="Yunlong Song" class="profile-image">
            </div>
            <div class="sidebar-links">
                <a href="https://scholar.google.com/citations?user=AQu2ugsAAAAJ&hl=en" title="Google Scholar">
                    <i class="fas fa-graduation-cap"></i>
                </a>
                <a href="https://github.com/percyhzy" title="GitHub">
                    <i class="fab fa-github"></i>
                </a>
                <a href="https://www.linkedin.com/in/zhenyu-hou-489640299" title="LinkedIn">
                    <i class="fab fa-linkedin"></i>
                </a>
            </div>
            <br>
            <a href="index.html" title="Home">Home</a>
            <br>
            <a href="project.html" title="Projects">Research Projects</a>
            <br>
            <a href="about.html" title="about">About Me</a>
        </div>

        <!-- 主内容区 -->
        <div class="main-content">
            <section class="project">
              <h2>Research Projects</h2>
              <p>
                I am passionate about developing algorithms for robots to perform complex tasks in the real world.
                Here are the projects I have worked on:
              </p>

              <div class="project-list">
                  <div class="project-item">
                      <div class="project-header">
                          <a href="#" class="project-title" onclick="toggleDescription(this)">
                              Real-time Spatial-temporal Traversability Assessment via Feature-based Sparse Gaussian Process
                              <span class="toggle-icon">▼</span>
                          </a>
                      </div>
                      <div class="project-description">
                          <p>
                           Proposed a global-map-free navigation framework for efficient autonomous robot navigation in complex terrains. 
                           The framework employs Sparse Gaussian Processes (SGP) to extract geometric features—such as curvature, gradient, and elevation—from point cloud data. GPU acceleration is used during feature extraction to ensure real-time performance. 
                           These features are integrated into a high-resolution local traversability map using a spatial-temporal Bayesian Gaussian Kernel Inference method that fuses historical and real-time data with slope, flatness, gradient, and uncertainty metrics. 
                           Extensive simulations demonstrate significant improvements in accuracy and computational efficiency compared to traditional methods. The framework is integrated into a planner and validated through autonomous navigation experiments on a real robot. 
                           Source code available at <a href="https://github.com/ZJU-FAST-Lab/FSGP_BGK">github.com/ZJU-FAST-Lab/FSGP_BGK</a>.
                          </p>
                          <video class="project-video" autoplay loop muted playsinline>
                              <source src="videos/IROS2025Percy.mp4" type="video/mp4">
                          </video>
                      </div>
                  </div>

                  <div class="project-item">
                      <div class="project-header">
                          <a href="#" class="project-title" onclick="toggleDescription(this)">
                              Autonomous Exploration in Simulator
                              <span class="toggle-icon">▼</span>
                          </a>
                      </div>
                      <div class="project-description">
                        <p>
                          Tested the <a href="https://github.com/ZJU-FAST-Lab/FastSim?tab=readme-ov-file">FastSim simulator</a>, integrating it with drone localization (using <a href="https://github.com/hku-mars/FAST_LIO">Fast-LIO</a>) and autonomous exploration (using <a href="https://github.com/HKUST-Aerial-Robotics/FUEL">FUEL</a>) algorithms for both structured and unstructured dark environments.
                        </p>
                        <video class="project-video" autoplay loop muted playsinline>
                          <source src="videos/splits.mp4" type="video/mp4">
                        </video>
                      </div>
                  </div>

                  <div class="project-item">
                      <div class="project-header">
                          <a href="#" class="project-title" onclick="toggleDescription(this)">
                              Aerial-Ground drone and quad-fisheye drone
                              <span class="toggle-icon">▼</span>
                          </a>
                      </div>
                      <div class="project-description">
                          <div class="video-text-container">
                             <p>
                              Developed an aerial-ground autonomous navigation system for drones using FAST-LIO and <a href="https://github.com/ZJU-FAST-Lab/ego-planner">ego-planner</a>. 
                              Achieved point cloud map relay sharing during exploration. Designed and built a quad-fisheye-based localization drone inspired by <a href="https://github.com/HKUST-Aerial-Robotics/OmniNxt">OmniNxt</a>, 
                              implementing VIO-based localization using <a href="https://docs.openvins.com/">OpenVINS</a>.
                            </p>
                            <video class="project-video project-video-small" autoplay loop muted playsinline>
                                <source src="videos/AutonomousFlight.mp4" type="video/mp4">
                            </video>
                          </div>
                      </div>
                  </div>

                  <div class="project-item">
                      <div class="project-header">
                          <a href="#" class="project-title" onclick="toggleDescription(this)">
                              Autonomous Flight and Swarm
                              <span class="toggle-icon">▼</span>
                          </a>
                      </div>
                      <div class="project-description">
                          <p>
                            Deployed lightweight drones equipped with VIO (<a href="https://github.com/HKUST-Aerial-Robotics/VINS-Fusion">VINS-fusion</a>) and autonomous flight using ego-planner. 
                            Conducted multi-drone VIO experiments using <a href="https://github.com/VIS4ROB-lab/covins">COVINS-G</a> and tested DM-VIO, ORB SLAM, and ALOAM.
                            Constructed an autonomous drone swarm employing a lidar-based <a href="https://github.com/ZJU-FAST-Lab/ego-planner-swarm">ego-swarm algorithm</a>, 
                            enabling independent flight in both outdoor sparse-feature environments and indoor structured settings.
                          </p>
                          <video class="project-video" autoplay loop muted playsinline>
                              <source src="videos/AutonomousFlight.mp4" type="video/mp4">
                          </video>
                      </div>
                  </div>

                  <div class="project-item">
                      <div class="project-header">
                          <a href="#" class="project-title" onclick="toggleDescription(this)">
                              Signal detection based on autonomous flight
                              <span class="toggle-icon">▼</span>
                          </a>
                      </div>
                      <div class="project-description">
                          <div class="video-text-container">
                              <p>
                                Developed a WiFi signal detection software for aerial-ground robots using PyQt and Linux networ interfaces. Air-Ground Robot Communication Planning Mesh Networking Problem
                                (Transmission of odometer information as well as map packets) with bandwidth, communication conditions and UAV energy as constraints for FUEL and ego-planner based UAV cluster
                                exploration problem.(It's a subject I'm planning to do in the future,I referenced the subT Challenge paper and methods,I considered trajectory optimisation and drop points for mobile relay nodes)
                                (This idea is inspired by MRS Group of CTU,from Professor Saska's paper)
                              </p>
                              <video class="project-video project-video-small" autoplay loop muted playsinline>
                                  <source src="videos/gt.mp4" type="video/mp4">
                              </video>
                          </div>
                      </div>
                  </div>

                  <div class="project-item">
                      <div class="project-header">
                          <a href="#" class="project-title" onclick="toggleDescription(this)">
                              2023 HKUST (GZ) Red Bird Challenge Camp
                              <span class="toggle-icon">▼</span>
                          </a>
                      </div>
                      <div class="project-description">
                          <div class="video-text-container">
                              <p>
                                The future of unmanned transport technology is rapidly developing, and the
                                scale of unmanned devices is expanding, while at the same time, labour costs are rising and the
                                demand for logistics is gradually increasing. Against this background, a project is proposed that
                                aims to achieve efficient logistics and distribution by integrating multiple unmanned devices so
                                that they can operate in concert and relay distribution under different demands. The project is
                                built on the carrier of the company, designed the company's organisational and system structure,
                                job division of labour, profit model. Technically, it solves the intelligent site selection problem of
                                the station of unmanned equipment, the path planning problem of unmanned equipment
                                receiving and distribution, as well as the intelligent communication and environment perception
                                problem between the equipment and the system security and interaction problem, and finally
                                carries out the pre-study of technical feasibility. 
                                <br><br>
                                <strong>Responsible for :</strong><br>
                                Implemented RRT and RRT* path planning and navigation for a quadruped robot in Gazebo; performed rendering simulations for both drones and quadruped robots using Blender.
                                Conducted GPS spoofing experiments using HackRF, validated spoofing on simulated target robots, and performed market research on potential solutions.
                                Market research, technical feasibility research, and technical organisation design of the company.
                                <br><br>
                                <strong>Awards:</strong><br>
                                2023 Outstanding Camper, Redbird Challenge Camp, HKUST
                              </p>
                              <video class="project-video project-video-small" autoplay loop muted playsinline>
                                  <source src="videos/gt.mp4" type="video/mp4">
                              </video>
                          </div>
                      </div>
                  </div>

                  <div class="project-item">
                      <div class="project-header">
                          <a href="#" class="project-title" onclick="toggleDescription(this)">
                              2021-2023 National University Robotics Competition RoboMaster Championship
                              <span class="toggle-icon">▼</span>
                          </a>
                      </div>
                      <div class="project-description">
                          <div class="video-text-container">
                              <p>
                                Project Introduction: National University Robotics Competition RoboMaster is a robotics event
                                jointly sponsored by the Central Committee of the Communist Youth League, the All-China
                                Federation of Schools and Colleges, the Chinese Academy of Engineering and the Shenzhen
                                Municipal People's Government, and initiated and hosted by DJI, as a global shooting
                                confrontation robotics competition.
                                <br><br>
                                <strong>Responsible for:</strong><br>
                                1. Laboratory creation: multiple negotiations with college and school
                                leaders, applying for funding, building the robotics lab from zero to one. 2023 seasons of collaboration with multiple schools (CAUC, SCU, SWU, DGUT, THU, etc.), about 40 people in the team.
                                <br>
                                2. Team Management: used Coding and Feishu to manage the project
                                and acceptance of results; established lab safety acceptance system.
                                <br>
                                3. Financial management: established a triple financial purchase reimbursement process
                                (team leader-captain-teacher), successfully obtained motor sponsorship from <a href="https://en.directdrive.com/">DirectDrive</a>.
                                <br>
                                4. Robot electronic control debugging: PID parameter tuning under
                                freeRTOS, applying cascaded PID control for a dual-degree-of-freedom gimbal, using inverse kinematics
                                for mecanum/omni wheels, verifying robustness, etc.
                                <br>
                                5. Wiring design: completed the topology design and actual wiring (signals and power supply) for
                                the Infantry, Hero, and Sentry robots.
                                <br>
                                6. Algorithm debugging: assisted the vision team in camera selection, calibration (Matlab, kalibar),
                                Docker-based environment, LIDAR + multi-camera fusion, radar calibration, YOLO detection on ROS,
                                3D printing, Gazebo simulation, etc.
                                <br><br>
                                <strong>Awards:</strong><br>
                                3rd place in the National <a href="https://www.robomaster.com/en-US">RoboMaster</a> Championship, 2023 (supported by DJI)<br>
                                2nd place in the National RoboMaster 3v3 League (Shanxi Division), 2023 (DJI)<br>
                                3rd place in the National RoboMaster 3v3 League, 2022 (DJI)
                              </p>
                              <video class="project-video project-video-small" autoplay loop muted playsinline>
                                  <source src="videos/gt.mp4" type="video/mp4">
                              </video>
                          </div>
                      </div>
                  </div>

                  <div class="project-item">
                      <div class="project-header">
                          <a href="#" class="project-title" onclick="toggleDescription(this)">
                              2018 FIRST Robotics Competition (FTC)
                              <span class="toggle-icon">▼</span>
                          </a>
                      </div>
                      <div class="project-description">
                          <div class="video-text-container">
                              <p>
                                <strong>Project Description:</strong> A youth robotics event under FIRST, supported by NASA and Qualcomm, to
                                develop robots that can perform fetching (sucking up specific targets as well as grasping specific
                                targets) and support both automatic and manual control.
                                <br><br>
                                <strong>Responsibilities:</strong><br>
                                1. External liaison, completing overall engineering notes, communication with the committee.<br>
                                2. Participated in mechanical construction and SolidWorks simulation design.
                                <br><br>
                                <strong>Awards:</strong><br>
                                Individual Award & Incentive Award, 2018 FIRST Robotics Competition (Suzhou)
                              </p>
                              <video class="project-video project-video-small" autoplay loop muted playsinline>
                                  <source src="videos/pendulum.mp4" type="video/mp4">
                              </video>
                          </div>
                      </div>
                  </div>
              </div>
            </section>
        </div>
    </div>

    <!-- 折叠/展开脚本 -->
    <script>
    function toggleDescription(element) {
        event.preventDefault();

        // Find the description div
        const description = element.closest('.project-item').querySelector('.project-description');
        const toggleIcon = element.querySelector('.toggle-icon');

        // Toggle visibility
        if (description.style.display === 'none') {
            description.style.display = 'block';
            toggleIcon.textContent = '▲';
        } else {
            description.style.display = 'none';
            toggleIcon.textContent = '▼';
        }
    }

    // On page load, set all project descriptions to be visible by default
    document.addEventListener('DOMContentLoaded', function() {
        const projectDescriptions = document.querySelectorAll('.project-description');
        const toggleIcons = document.querySelectorAll('.toggle-icon');

        projectDescriptions.forEach(description => {
            description.style.display = 'block';
        });

        toggleIcons.forEach(icon => {
            icon.textContent = '▲';
        });
    });
    </script>
</body>
</html>
