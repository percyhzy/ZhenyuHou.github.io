<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Research Projects - Yunlong Song</title>
    <link rel="stylesheet" href="style.css">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Font Awesome for modern icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
</head>
<body>
    <div class="container">
        <div class="sidebar">
            <div class="profile-image-container">
                <img src="images/me.jpg" alt="Yunlong Song" class="profile-image">
            </div>
<div class="sidebar-links">
                <a href="https://scholar.google.com/citations?user=AQu2ugsAAAAJ&hl=en" title="Google Scholar">
                    <i class="fas fa-graduation-cap"></i>
                </a>
                <a href="https://github.com/percyhzy" title="GitHub">
                    <i class="fab fa-github"></i>
                </a>
                <a href="https://www.linkedin.com/in/zhenyu-hou-489640299" title="LinkedIn">
                    <i class="fab fa-linkedin"></i>
                </a>
            </div>
            <br>
            <a href="index.html" title="Home">Home</a>
            <br>
            <a href="project.html" title="Projects">Research Projects</a>
            <br>
            <a href="opensource.html" title="OpenSource">Open-source Code</a>
            <br>
            <a href="about.html" title="about">About Me</a>
        </div>

        <div class="main-content">
            <section class="project">
            <h2>Research Projects</h2>
            <p>
              I am passionate about developing algorithms for robots to perform complex tasks in the real world.
              Here are the projects I have worked on:
            </p>
          <div class="project-list">

              <div class="project-item">
                  <div class="project-header">
                      <a href="#" class="project-title" onclick="toggleDescription(this)">
                          Real-time Spatial-temporal Traversability Assessment via Feature-based Sparse Gaussian Process
                          <span class="toggle-icon">▼</span>
                      </a>
                  </div>
                  <div class="project-description">
                      <!-- <div class="video-text-container"> -->
                          <p>
                           Proposed a global-map-free navigation framework for efficient autonomous robot navigation in complex terrains. 
                           The framework employs Sparse Gaussian Processes (SGP) to extract geometric features—such as curvature, gradient, and elevation—from point cloud data. GPU acceleration is used during feature extraction to ensure real-time performance. 
                           These features are integrated into a high-resolution local traversability map using a spatial-temporal Bayesian Gaussian Kernel Inference method that fuses historical and real-time data with slope, flatness, gradient, and uncertainty metrics. 
                           Extensive simulations demonstrate significant improvements in accuracy and computational efficiency compared to traditional methods. The framework is integrated into a planner and validated through autonomous navigation experiments on a real robot. 
                           Source code available at <a href="https://github.com/ZJU-FAST-Lab/FSGP_BGK">github.com/ZJU-FAST-Lab/FSGP\_BGK</a>.
                          </p>
                          <video class="project-video" autoplay loop muted playsinline>
                              <source src="videos/IROSVideo.mp4" type="video/mp4">
                          </video>
                      <!-- </div> -->
                  </div>
              </div>

              <div class="project-item">
                  <div class="project-header">
                      <a href="#" class="project-title" onclick="toggleDescription(this)">
                          Autonomous Exploration in Simulator
                          <span class="toggle-icon">▼</span>
                      </a>
                  </div>
<div class="project-description">
  <p>
    Tested the <a href="https://github.com/ZJU-FAST-Lab/FastSim?tab=readme-ov-file">FastSim simulator</a>, integrating it with drone localization (using <a href="https://github.com/hku-mars/FAST_LIO">Fast-LIO</a>) and autonomous exploration (using <a href="https://github.com/HKUST-Aerial-Robotics/FUEL">FUEL</a>) algorithms for both structured and unstructured dark environments.
  </p>
  <video class="project-video" autoplay loop muted playsinline>
    <source src="videos/splits.mp4" type="video/mp4">
  </video>
</div>

              </div>


              <div class="project-item">
                  <div class="project-header">
                      <a href="#" class="project-title" onclick="toggleDescription(this)">
                          Aerial-Ground drone and quad-fisheye drone
                          <span class="toggle-icon">▼</span>
                      </a>
                  </div>
                  <div class="project-description">
                      <div class="video-text-container">
                         <p>
                          Developed an aerial-ground autonomous navigation system for drones using FAST-LIO and <a href="https://github.com/ZJU-FAST-Lab/ego-planner">ego-planner</a>. 
                          Achieved point cloud map relay sharing during exploration. Designed and built a quad-fisheye-based localization drone inspired by <a href="https://github.com/HKUST-Aerial-Robotics/OmniNxt">OmniNxt</a>, 
                          implementing VIO-based localization using <a href="https://docs.openvins.com/">OpenVINS</a>.
                        </p>

                          <video class="project-video project-video-small" autoplay loop muted playsinline>
                              <source src="videos/cheetah.mp4" type="video/mp4">
                          </video>
                      </div>
                  </div>
              </div>


              <div class="project-item">
                  <div class="project-header">
                      <a href="#" class="project-title" onclick="toggleDescription(this)">
                          Autonomous Flight and Swarm
                          <span class="toggle-icon">▼</span>
                      </a>
                  </div>
                  <div class="project-description">
                      <!-- <div class="video-text-container"> -->
                          <p>
                            Deployed lightweight drones equipped with VIO (<a href="https://github.com/HKUST-Aerial-Robotics/VINS-Fusion">VINS-fusion</a>) and autonomous flight using ego-planner. 
                            Conducted multi-drone VIO experiments using <a href="https://github.com/VIS4ROB-lab/covins">COVINS-G</a> and tested DM-VIO, ORB SLAM, and ALOAM.
                            Constructed an autonomous drone swarm employing a lidar-based <a href="https://github.com/ZJU-FAST-Lab/ego-planner-swarm">ego-swarm algorithm</a>, 
                            enabling independent flight in both outdoor sparse-feature environments and indoor structured settings.
                          </p>

                          <video class="project-video" autoplay loop muted playsinline>
                              <source src="videos/highmpc.mp4" type="video/mp4">
                          </video>
                      <!-- </div> -->
                  </div>
              </div>

              <div class="project-item">
                  <div class="project-header">
                      <a href="#" class="project-title" onclick="toggleDescription(this)">
                          Signal detection based on autonomous flight
                          <span class="toggle-icon">▼</span>
                      </a>
                  </div>
                  <div class="project-description">
                      <div class="video-text-container">
                          <p>
                            Developed a WiFi signal detection software for aerial-ground robots using PyQt and Linux networ interfaces.Air-Ground Robot Communication Planning Mesh Networking Problem
                            (Transmission of odometer information as well as map packets) with bandwidth, communication conditions and UAV energy as constraints for FUEL and ego-planner based UAV cluster
                            exploration problem.(It's a subject I'm planning to do in the future,I referenced the subT Challenge paper and methods,I considered trajectory optimisation and drop points for mobile relay nodes)
                           （This idea is inspired by MRS Group of CTU,from Professor Saska's paper)
                
                          </p>
                          <video class="project-video project-video-small" autoplay loop muted playsinline>
                              <source src="videos/gt.mp4" type="video/mp4">
                          </video>
                      </div>
                  </div>
              </div>
              <div class="project-item">
                  <div class="project-header">
                      <a href="#" class="project-title" onclick="toggleDescription(this)">
                          2023 HKUST (GZ) Red Bird Challenge Camp
                          <span class="toggle-icon">▼</span>
                      </a>
                  </div>
                  <div class="project-description">
                      <div class="video-text-container">
                          <p>
                            The future of unmanned transport technology is rapidly developing, and the
                            scale of unmanned devices is expanding, while at the same time, labour costs are rising and the
                            demand for logistics is gradually increasing. Against this background, a project is proposed that
                            aims to achieve efficient logistics and distribution by integrating multiple unmanned devices so
                            that they can operate in concert and relay distribution under different demands. The project is
                            built on the carrier of the company, designed the company's organisational and system structure,
                            job division of labour, profit model. Technically, it solves the intelligent site selection problem of
                            the station of unmanned equipment, the path planning problem of unmanned equipment
                            receiving and distribution, as well as the intelligent communication and environment perception
                            problem between the equipment and the system security and interaction problem, and finally
                            carries out the pre-study of technical feasibility. 
                            Responsible for :
                            Implemented RRT and RRT* path planning and navigation for a quadruped robot in Gazebo; performed rendering simulations for both drones and quadruped robots using Blender.
                            Conducted GPS spoofing experiments using HackRF, validated spoofing on simulated target robots, and performed market research on potential solutions.
                            Market research, technical feasibility research, and technical organisation design of the company;
                            Awards:
                            2023 Outstanding Camper, Redbird Challenge Camp, HKUST
                          </p>
                          <video class="project-video project-video-small" autoplay loop muted playsinline>
                              <source src="videos/gt.mp4" type="video/mp4">
                          </video>
                      </div>
                  </div>
              </div>

                          <div class="project-item">
                  <div class="project-header">
                      <a href="#" class="project-title" onclick="toggleDescription(this)">
                          2021-2023 National University Robotics Competition RoboMaster Championship, Single Match, League Match 
                          <span class="toggle-icon">▼</span>
                      </a>
                  </div>
                  <div class="project-description">
                      <div class="video-text-container">
                          <p>
                          Project Introduction ： National University Robotics Competition RoboMaster is a robotics event
                          jointly sponsored by the Central Committee of the Communist Youth League, the All-China
                          Federation of Schools and Colleges, the Chinese Academy of Engineering and the Shenzhen
                          Municipal People's Government, and initiated and hosted by DJI, as a global shooting
                          confrontation robotics competition.
                          Responsible for matters :
                          1.Laboratory creation: I have communicated and negotiated with the college and school
                          leaders for many times, applied for funding, and completed the formation of the robotics
                          laboratory from zero to one. 2023 seasons of collaboration with multiple schools, the team includes
                          CAUC, SCU, SWU, DGUT, THU and other colleges and universities, the size of the team of about 40
                          people.
                          2.Team Management: Adopt Coding and Flying Book to carry out scientific project management
                          and acceptance of results; establish laboratory safety acceptance system.
                          3.Financial investment management: establish a triple financial purchase reimbursement process
                          of team leader-captain-teacher, and successfully securing motor sponsorship from \href{https://en.directdrive.com/}{DirectDrive} .
                          4. Robot electronic control debugging: PID parameter debugging of each part of motor under
                          freeRTOS, robustness verification, application of cascaded PID control or a dual-degree-of-freedom gimbal, application of inverse kinematics
                          solution of McNamee wheel and omnidirectional wheel.
                          5. Wiring design: Completed the topology design and actual wiring (signals and power supply) for
                          the Infantry, Hero, and Sentry robots.
                          6. Robot algorithm debugging: assisted the vision team in camera selection, calibration（used Matlab and kalibar）,
                          system environment construction by Docker,completed the joint calibration of LIDAR and multi-camera sensor fusion;
                          conducting radar calibration, designed and deployed target detection algorithms using both traditional OpenCV and YOLO on ROS, 
                          performed pose estimation, Gazebo simulation, and utilized 3D printing.
                          Awards：
                          3rd place in the National \href{https://www.robomaster.com/en-US}{RoboMaster} (Championship) competition, 2023 (supported by \textbf{DJI})
                          2nd place in the National RoboMaster 3v3 League (Shanxi Division) competition, 2023 (supported by \textbf{DJI})
                          3rd place in the National RoboMaster 3v3 League competition, 2022 (supported by \textbf{DJI})
                
                          </p>
                          <video class="project-video project-video-small" autoplay loop muted playsinline>
                              <source src="videos/gt.mp4" type="video/mp4">
                          </video>
                      </div>
                  </div>
              </div>

              <div class="project-item">
                  <div class="project-header">
                      <a href="#" class="project-title" onclick="toggleDescription(this)">
                          2018 FIRST Robotics Competition (FTC)
                          <span class="toggle-icon">▼</span>
                      </a>
                  </div>
                  <div class="project-description">
                      <div class="video-text-container">
                          <p>
                            Project Description : A youth robotics event under FIRST, supported by NASA and Qualcomm, to
                            develop robots that can perform fetching (sucking up specific targets as well as grasping specific
                            targets) and support both automatic and manual control;
                            Responsibilities:
                            1.Responsible for external liaison, completing the overall writing of engineering notes and
                            communicating with the competition organising committee.
                            2. Participate in the mechanical construction of the robot and assist in soildworks simulation
                            design.
                            Awards:
                            Individual Award & Incentive Award, 2018 FIRST Robotics Competition (Suzhou )
                          </p>
                          <video class="project-video project-video-small" autoplay loop muted playsinline>
                              <source src="videos/pendulum.mp4" type="video/mp4">
                          </video>
                      </div>
                  </div>
              </div>
          </div>
        </section>
    </div>
    <script>
    function toggleDescription(element) {
        // Prevent default link behavior
        event.preventDefault();

        // Find the description div
        const description = element.closest('.project-item').querySelector('.project-description');
        const toggleIcon = element.querySelector('.toggle-icon');

        // Toggle visibility
        if (description.style.display === 'none') {
            description.style.display = 'block';
            toggleIcon.textContent = '▲';
        } else {
            description.style.display = 'none';
            toggleIcon.textContent = '▼';
        }
    }

    // On page load, set all project descriptions to be visible by default
    document.addEventListener('DOMContentLoaded', function() {
        const projectDescriptions = document.querySelectorAll('.project-description');
        const toggleIcons = document.querySelectorAll('.toggle-icon');

        projectDescriptions.forEach(description => {
            description.style.display = 'block';
        });

        toggleIcons.forEach(icon => {
            icon.textContent = '▲';
        });
    });
    </script>
</body>
</html>
